# Ollama Kurulum Kılavuzu

![https://ollama.com/public/blog/libraries.svg](https://ollama.com/public/blog/libraries.svg)



## Sistem Gereksinimleri

Ollama kurulumuna başlamadan önce, sisteminizin asgari gereksinimleri karşıladığından emin olmalısınız. Desteklenen işletim sistemleri macOS, Linux ve Windows'tur. Docker kurulumu da alternatif bir yöntem olarak kullanılabilir.



## MacOS için Kurulum Adımları

MacOS'ta kurulum oldukça basittir. Homebrew paket yöneticisi kullanarak veya doğrudan indirme yöntemiyle kurulum yapabilirsiniz.



### Homebrew ile Kurulum

Terminal'i açın ve şu komutu çalıştırın:

```bash
brew install ollama
```

Kurulum tamamlandıktan sonra Ollama'yı başlatmak için:

```bash
ollama serve
```



### Manuel Kurulum

1. Ollama'nın resmi web sitesinden (https://ollama.ai) macOS için kurulum dosyasını indirin
2. İndirilen .dmg dosyasını çift tıklayarak açın
3. Ollama uygulamasını Applications klasörüne sürükleyin
4. Applications klasöründen Ollama'yı başlatın



## Linux için Kurulum Adımları

Linux sistemlerde kurulum için terminal kullanmanız gerekiyor:

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

Kurulum tamamlandıktan sonra Ollama'yı başlatmak için:

```bash
ollama serve
```



## Windows için Kurulum Adımları

Windows'ta kurulum için WSL2 (Windows Subsystem for Linux 2) gereklidir:

1. PowerShell'i yönetici olarak açın
2. WSL2'yi etkinleştirin:

```powershell
wsl --install
```

3. Bilgisayarınızı yeniden başlatın
4. Linux dağıtımını (örneğin Ubuntu) Microsoft Store'dan indirip kurun
5. WSL terminalinde Linux kurulum adımlarını takip edin



## Kurulumu Doğrulama

Kurulumun başarılı olduğunu doğrulamak için:

```bash
ollama --version
```



## Model İndirme ve Çalıştırma

İlk modeli indirmek ve çalıştırmak için:

```bash
ollama run llama2
```

Bu komut, Llama 2 modelini indirecek ve etkileşimli bir sohbet oturumu başlatacaktır.



## Güvenlik Duvarı Ayarları

Eğer güvenlik duvarı engelliyorsa, Ollama'nın varsayılan olarak 11434 portunu kullandığını unutmayın. Bu portu güvenlik duvarı ayarlarınızda açmanız gerekebilir.

Kurulum tamamlandıktan sonra, Ollama'yı kullanmaya başlamadan önce sistemin stabil çalıştığından emin olmak için birkaç basit test yapmanızı öneririm.







# Ollama (Context) ve Model İndirme Rehberi



![](https://cloudkitect.com/wp-content/uploads/2024/09/ContextWindowLimitation-1024x629.webp)

## Context (Bağlam) Nedir?

Yapay zeka modellerindeki "context" yani bağlam, modelin bir seferde işleyebileceği ve hatırlayabileceği metin miktarını ifade eder. Bunu bir insanın kısa süreli hafızası gibi düşünebilirsiniz.

Örnek olarak düşünelim:
- 4K context = Yaklaşık 4 sayfalık metin
- 8K context = Yaklaşık 8 sayfalık metin
- 16K context = Yaklaşık 16 sayfalık metin



![](https://pathmonk.com/wp-content/uploads/2023/08/Prompt-Engineering-Effectively-A-Marketers-Guide-to-Mastering-Prompt-Engineering-1024x585.png)





## Model İndirirken Dikkat Edilmesi Gerekenler



### 1. Sistem Gereksinimleri

Her modelin farklı bellek (RAM) gereksinimleri vardır. Örneğin:
- Küçük modeller: 4-8 GB RAM
- Orta boy modeller: 8-16 GB RAM 
- Büyük modeller: 16+ GB RAM gerektirebilir



### 2. Model Boyutu ve İndirme Süresi
```bash
# Örnek indirme komutu
ollama pull llama2

# Model bilgilerini görüntüleme
ollama list
```



Modelin boyutuna göre internet hızınıza bağlı olarak indirme süresi değişecektir. 



Örneğin:

- Küçük model (2-3 GB): Hızlı internet bağlantısıyla 5-10 dakika
- Büyük model (10+ GB): 30 dakika veya daha fazla sürebilir



### 3. Context Seçimi

- Kısa yazılar ve sohbetler için: 4K context yeterli olabilir
- Uzun metinler ve dökümanlar için: 8K veya daha yüksek context gerekebilir
- Kitap analizi gibi işler için: 16K+ context tercih edilebilir



### 4. Model Kalitesi

https://ollama.com/search adresinden:
- Modelin puanına bakın
- Kullanıcı yorumlarını okuyun
- Model açıklamasını inceleyin



### 5. Pratik İpuçları

İndirme işlemi sırasında:
```bash
# İndirme durumunu görüntüleme
ollama list

# İndirme işlemini durdurma
CTRL + C

# Modeli silme
ollama rm model_adı
```



Başlangıç için önerilen modeller:

- llama2: Genel amaçlı, dengeli bir model
- mistral: Hızlı ve verimli
- phi: Küçük boyutlu, başlangıç için ideal



Her model farklı güçlü yönlere sahiptir. Örneğin bazı modeller kod yazmada, bazıları yaratıcı yazarlıkta daha iyidir. Kendi ihtiyaçlarınıza en uygun modeli seçmek önemlidir.