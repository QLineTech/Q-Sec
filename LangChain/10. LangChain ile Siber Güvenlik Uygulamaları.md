# LangChain ile Siber Güvenlik Uygulamaları



Bu eğitimde LangChain'i siber güvenlik ve sızma testi uygulamalarında nasıl kullanacağımızı öğreneceğiz. Groq'u LLM (Büyük Dil Modeli) olarak kullanacağız.



## LangChain Nedir?

LangChain, yapay zeka uygulamaları geliştirmemizi kolaylaştıran bir araçtır. 

Düşünün ki bir aşçısınız ve farklı malzemeleri birleştirerek yemek yapıyorsunuz - LangChain de yapay zeka uygulamalarını farklı parçaları birleştirerek yapmamızı sağlar.



![](https://www.ksolves.com/wp-content/uploads/2024/07/LangChain-Benefits.png)



### LangChain.Chains Nedir?
Chains (Zincirler), LangChain'in en temel yapı taşlarından biridir. Bir zincir, birden fazla işlemi sırayla veya belirli bir mantıkla yürütmemizi sağlar. Günlük hayattan bir örnekle açıklayalım:

Bir restoranda yemek siparişi düşünün:
1. Garson siparişi alır (Input)
2. Sipariş mutfağa iletilir (İlk işlem)
3. Yemek hazırlanır (İkinci işlem)
4. Müşteriye servis edilir (Output)

LangChain'deki zincirler de benzer şekilde çalışır:

```python
# Basit bir zincir örneği
from langchain.chains import LLMChain

# Tek adımlı zincir
simple_chain = LLMChain(llm=llm, prompt=prompt)

# Çok adımlı zincir
from langchain.chains import SequentialChain
multi_chain = SequentialChain(
    chains=[chain1, chain2, chain3],
    input_variables=["input"],
    output_variables=["final_output"]
)
```



# **Zincir Türleri:**

- LLMChain: En temel zincir türü, bir LLM ile bir prompt'u birleştirir
- SequentialChain: Birden fazla zinciri sırayla çalıştırır
- RouterChain: Girdiye göre farklı zincirlere yönlendirme yapar
- TransformChain: Veriyi dönüştürme işlemleri için kullanılır





### LangChain.Prompts Nedir?
Prompts (Komutlar), LLM'e ne yapması gerektiğini söyleyen şablonlardır. Bir öğretmene ödev talimatı vermeye benzer:

```python
from langchain.prompts import PromptTemplate

# Basit bir prompt şablonu
basic_prompt = PromptTemplate(
    input_variables=["website"],
    template="Bu websitesinin güvenlik açıklarını analiz et: {website}"
)

# Daha karmaşık bir prompt şablonu
detailed_prompt = PromptTemplate(
    input_variables=["target", "scan_type", "severity"],
    template="""
    Hedef: {target}
    Tarama Türü: {scan_type}
    Önem Seviyesi: {severity}
    
    Lütfen aşağıdaki analizleri gerçekleştirin:
    1. Potansiyel güvenlik açıkları
    2. Risk değerlendirmesi
    3. Çözüm önerileri
    """
)

# Sohbet tarzı prompt şablonu
from langchain.prompts import ChatPromptTemplate
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "Sen bir siber güvenlik uzmanısın."),
    ("user", "{user_input}"),
    ("assistant", "Analiz sonuçları: {analysis}")
])
```



### Prompt Şablonu Oluşturma Detayları

Prompt şablonları oluştururken dikkat edilmesi gerekenler:

1. **Değişken Tanımlama:**
````python
# LangChain ile Siber Güvenlik Uygulamaları

## Giriş
Merhaba! Bu eğitimde LangChain'i siber güvenlik ve sızma testi uygulamalarında nasıl kullanacağımızı öğreneceğiz. Groq'u LLM (Büyük Dil Modeli) olarak kullanacağız.

## LangChain Nedir?
LangChain, yapay zeka uygulamaları geliştirmemizi kolaylaştıran bir araçtır. Düşünün ki bir aşçısınız ve farklı malzemeleri birleştirerek yemek yapıyorsunuz - LangChain de yapay zeka uygulamalarını farklı parçaları birleştirerek yapmamızı sağlar.

### LangChain.Chains Nedir?
Chains (Zincirler), LangChain'in en temel yapı taşlarından biridir. Bir zincir, birden fazla işlemi sırayla veya belirli bir mantıkla yürütmemizi sağlar. Günlük hayattan bir örnekle açıklayalım:

Bir restoranda yemek siparişi düşünün:
1. Garson siparişi alır (Input)
2. Sipariş mutfağa iletilir (İlk işlem)
3. Yemek hazırlanır (İkinci işlem)
4. Müşteriye servis edilir (Output)

LangChain'deki zincirler de benzer şekilde çalışır:

```python
# Basit bir zincir örneği
from langchain.chains import LLMChain

# Tek adımlı zincir
simple_chain = LLMChain(llm=llm, prompt=prompt)

# Çok adımlı zincir
from langchain.chains import SequentialChain
multi_chain = SequentialChain(
    chains=[chain1, chain2, chain3],
    input_variables=["input"],
    output_variables=["final_output"]
)
```

### Zincir (Chain) Türleri ve Örnekler

#### 1. LLMChain
En temel zincir türüdür. Bir LLM ile bir prompt'u birleştirir. Düşünün ki bir restoranda garsonun siparişi aşçıya iletmesi gibidir.

Örnek 1 - Güvenlik Açığı Analizi:
```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# Güvenlik açığı analiz zinciri
vuln_template = PromptTemplate(
    input_variables=["vulnerability"],
    template="Bu güvenlik açığını analiz et: {vulnerability}\n1. Risk seviyesi\n2. Olası etkiler\n3. Çözüm önerileri"
)

vuln_chain = LLMChain(
    llm=llm,
    prompt=vuln_template,
    verbose=True  # İşlem adımlarını görmek için
)

# Kullanımı
result = vuln_chain.run("Login sayfasında SSL sertifikası eksik")
```

Örnek 2 - Port Tarama Analizi:
```python
# Port tarama sonuçlarını değerlendirme zinciri
port_template = PromptTemplate(
    input_variables=["ports"],
    template="""
    Bu port tarama sonuçlarını değerlendir:
    {ports}
    
    Lütfen şunları belirt:
    1. Açık portların riskleri
    2. Kapatılması gereken portlar
    3. Güvenlik tavsiyeleri
    """
)

port_chain = LLMChain(
    llm=llm,
    prompt=port_template
)

# Kullanımı
scan_results = "22/tcp open, 80/tcp open, 3306/tcp open"
analysis = port_chain.run(scan_results)
```

#### 2. SequentialChain
Birden fazla zinciri sırayla çalıştırır. Bu, bir fabrikadaki üretim bandına benzer - her istasyon bir öncekinin çıktısını alır ve işler.

Örnek 1 - Kapsamlı Güvenlik Analizi:
```python
from langchain.chains import SequentialChain

# İlk zincir: Port taraması analizi
port_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["ports"],
        template="Port tarama sonuçlarını analiz et: {ports}"
    ),
    output_key="port_analysis"
)

# İkinci zincir: Güvenlik önerileri
recommendation_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["port_analysis"],
        template="Bu analiz sonuçlarına göre güvenlik önerileri sun: {port_analysis}"
    ),
    output_key="recommendations"
)

# Üçüncü zincir: Rapor oluşturma
report_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["port_analysis", "recommendations"],
        template="Port analizi: {port_analysis}\nÖneriler: {recommendations}\n\nBunları profesyonel bir rapora dönüştür."
    ),
    output_key="final_report"
)

# Zincirleri birleştirme
security_analysis = SequentialChain(
    chains=[port_chain, recommendation_chain, report_chain],
    input_variables=["ports"],
    output_variables=["final_report"],
    verbose=True
)

# Kullanımı
result = security_analysis.run("22/tcp open, 80/tcp open, 3306/tcp open")
```

Örnek 2 - Zafiyet Analiz Süreci:
```python
# İlk zincir: Zafiyet tespiti
vulnerability_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["system_info"],
        template="Bu sistemdeki olası güvenlik açıklarını belirle: {system_info}"
    ),
    output_key="vulnerabilities"
)

# İkinci zincir: Risk değerlendirmesi
risk_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["vulnerabilities"],
        template="Bu güvenlik açıklarının risk seviyelerini değerlendir: {vulnerabilities}"
    ),
    output_key="risk_assessment"
)

# Zincirleri birleştirme
vuln_assessment = SequentialChain(
    chains=[vulnerability_chain, risk_chain],
    input_variables=["system_info"],
    output_variables=["risk_assessment"]
)

# Kullanımı
system_info = "Windows Server 2012, IIS 7.0, MySQL 5.5"
assessment = vuln_assessment.run(system_info)
```

#### 3. RouterChain
Girdiye göre farklı zincirlere yönlendirme yapar. Bu, bir hastanedeki triyaj hemşiresinin hastaları durumlarına göre farklı bölümlere yönlendirmesine benzer.

Örnek 1 - Güvenlik Olayı Sınıflandırma:
```python
from langchain.chains.router import MultiPromptChain
from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
from langchain.prompts import PromptTemplate

# Farklı olay türleri için zincirler
malware_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="Bu malware olayını analiz et: {input}",
        input_variables=["input"]
    )
)

phishing_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="Bu phishing saldırısını analiz et: {input}",
        input_variables=["input"]
    )
)

ddos_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="Bu DDoS saldırısını analiz et: {input}",
        input_variables=["input"]
    )
)

# Yönlendirme şablonu
router_template = """Aşağıdaki güvenlik olayının türünü belirle ve uygun analiz zincirine yönlendir:
{input}

Olası kategoriler:
1. malware
2. phishing
3. ddos

Format olarak kategori ismini döndür."""

# Router zinciri oluşturma
router_chain = LLMRouterChain.from_llm(
    llm,
    router_template,
    RouterOutputParser()
)

# Tüm zincirleri birleştirme
chain = MultiPromptChain(
    router_chain=router_chain,
    destination_chains={
        "malware": malware_chain,
        "phishing": phishing_chain,
        "ddos": ddos_chain
    },
    default_chain=malware_chain,
    verbose=True
)

# Kullanımı
incident = "Sistemde şüpheli .exe dosyası tespit edildi"
analysis = chain.run(incident)
```

Örnek 2 - Güvenlik Açığı Önceliklendirme:
```python
# Farklı risk seviyeleri için zincirler
high_risk_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="ACİL - Yüksek Riskli Açık: {input}\nHemen müdahale planı oluştur.",
        input_variables=["input"]
    )
)

medium_risk_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="UYARI - Orta Riskli Açık: {input}\n24 saat içinde müdahale planı oluştur.",
        input_variables=["input"]
    )
)

low_risk_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        template="BİLGİ - Düşük Riskli Açık: {input}\nRutin kontroller sırasında değerlendir.",
        input_variables=["input"]
    )
)

# Yönlendirme şablonu
risk_router_template = """Bu güvenlik açığının risk seviyesini değerlendir:
{input}

Risk seviyeleri:
1. high (CVSS >= 7.0)
2. medium (CVSS 4.0-6.9)
3. low (CVSS < 4.0)

Sadece risk seviyesini döndür (high/medium/low)."""

# Router zinciri
risk_router = LLMRouterChain.from_llm(
    llm,
    risk_router_template,
    RouterOutputParser()
)

# Zincirleri birleştirme
risk_chain = MultiPromptChain(
    router_chain=risk_router,
    destination_chains={
        "high": high_risk_chain,
        "medium": medium_risk_chain,
        "low": low_risk_chain
    },
    default_chain=medium_risk_chain,
    verbose=True
)

# Kullanımı
vulnerability = "SQL Injection açığı tespit edildi - CVSS: 8.5"
response = risk_chain.run(vulnerability)
```

#### 4. TransformChain
Veriyi dönüştürme işlemleri için kullanılır. Bu, bir çevirmene benzer - aldığı veriyi işleyip farklı bir formatta sunar.

Örnek 1 - Log Formatı Dönüştürme:
```python
from langchain.chains import TransformChain

def log_transformer(inputs: dict) -> dict:
    """Ham log verilerini yapılandırılmış formata dönüştürür"""
    raw_log = inputs["raw_log"]
    
    # Log parçalama işlemi
    parts = raw_log.split(" ")
    
    return {
        "timestamp": parts[0],
        "ip_address": parts[1],
        "event_type": parts[2],
        "details": " ".join(parts[3:])
    }

# Dönüştürme zinciri oluşturma
log_transform_chain = TransformChain(
    input_variables=["raw_log"],
    output_variables=["timestamp", "ip_address", "event_type", "details"],
    transform=log_transformer
)

# Kullanımı
raw_log = "2024-01-09T10:15:30 192.168.1.100 LOGIN_ATTEMPT Failed password for admin"
structured_log = log_transform_chain.run(raw_log)
```

Örnek 2 - Nmap Çıktısı Dönüştürme:
```python
def nmap_transformer(inputs: dict) -> dict:
    """Nmap çıktısını yapılandırılmış rapora dönüştürür"""
    raw_scan = inputs["scan_output"]
    
    # Portları ayırma
    open_ports = []
    filtered_ports = []
    
    for line in raw_scan.split("\n"):
        if "open" in line:
            port = line.split("/")[0]
            open_ports.append(port)
        elif "filtered" in line:
            port = line.split("/")[0]
            filtered_ports.append(port)
    
    return {
        "open_ports": ", ".join(open_ports),
        "filtered_ports": ", ".join(filtered_ports),
        "total_open": len(open_ports),
        "total_filtered": len(filtered_ports),
        "risk_level": "High" if len(open_ports) > 5 else "Medium"
    }

# Dönüştürme zinciri
nmap_transform_chain = TransformChain(
    input_variables=["scan_output"],
    output_variables=["open_ports", "filtered_ports", "total_open", "total_filtered", "risk_level"],
    transform=nmap_transformer
)

# Kullanımı
nmap_output = """
22/tcp open ssh
80/tcp open http
443/tcp filtered https
3306/tcp filtered mysql
"""
scan_report = nmap_transform_chain.run(nmap_output)
```

### LangChain.Prompts Nedir?
Prompts (Komutlar), LLM'e ne yapması gerektiğini söyleyen şablonlardır. Bir öğretmene ödev talimatı vermeye benzer:

```python
from langchain.prompts import PromptTemplate

# Basit bir prompt şablonu
basic_prompt = PromptTemplate(
    input_variables=["website"],
    template="Bu websitesinin güvenlik açıklarını analiz et: {website}"
)

# Daha karmaşık bir prompt şablonu
detailed_prompt = PromptTemplate(
    input_variables=["target", "scan_type", "severity"],
    template="""
    Hedef: {target}
    Tarama Türü: {scan_type}
    Önem Seviyesi: {severity}
    
    Lütfen aşağıdaki analizleri gerçekleştirin:
    1. Potansiyel güvenlik açıkları
    2. Risk değerlendirmesi
    3. Çözüm önerileri
    """
)

# Sohbet tarzı prompt şablonu
from langchain.prompts import ChatPromptTemplate
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "Sen bir siber güvenlik uzmanısın."),
    ("user", "{user_input}"),
    ("assistant", "Analiz sonuçları: {analysis}")
])
```

### Prompt Şablonu Oluşturma Detayları

Prompt şablonları oluştururken dikkat edilmesi gerekenler:

1. Değişken Tanımlama:
```python
# Tek değişkenli şablon
simple_template = PromptTemplate(
    input_variables=["query"],
    template="Soru: {query}\nCevap:"
)

# Çok değişkenli şablon
complex_template = PromptTemplate(
    input_variables=["url", "method", "headers"],
    template="""
    URL: {url}
    Metod: {method}
    Başlıklar: {headers}
    
    Bu HTTP isteğini güvenlik açısından değerlendir.
    """
)
```

2. Partial Promptlar:
```python
from langchain.prompts import PromptTemplate
# Bazı değişkenleri önceden doldurma
base_template = PromptTemplate(
    input_variables=["url", "scan_type"],
    template="URL: {url}\nTarama Türü: {scan_type}"
)

# Tarama türünü sabit yapma
nmap_template = base_template.partial(scan_type="Nmap")
```

3. Şartlı Şablonlar:
```python
conditional_template = PromptTemplate(
    input_variables=["vulnerability", "severity"],
    template="""
    Açık: {vulnerability}
    Seviye: {severity}
    
    {%- if severity == "Yüksek" %}
    ACİL: Hemen müdahale gerekiyor!
    {%- elif severity == "Orta" %}
    UYARI: 24 saat içinde müdahale edilmeli.
    {%- else %}
    BİLGİ: Rutin kontroller sırasında değerlendirilmeli.
    {%- endif %}
    """
)
```

### LangChain'in Temel Komutları

1. LLM İşlemleri:
```python
# LLM başlatma
from langchain_groq import ChatGroq
llm = ChatGroq(api_key="your-api-key")

# Basit soru-cevap
response = llm.predict("Bir SQL injection nedir?")

# Sohbet tarzı etkileşim
messages = [
    ("system", "Sen bir güvenlik uzmanısın"),
    ("user", "XSS açığı nedir?")
]
response = llm.predict_messages(messages)
```

2. Bellek (Memory) İşlemleri:
```python
from langchain.memory import ConversationBufferMemory

# Basit bellek
memory = ConversationBufferMemory()

# Bellekli zincir
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory
)
```

3. Araç (Tools) Kullanımı:
```python
from langchain.tools import DuckDuckGoSearchRun
from langchain.tools import PythonREPLTool

# Arama aracı
search = DuckDuckGoSearchRun()
result = search.run("Son çıkan CVE'ler")

# Python REPL aracı
python = PythonREPLTool()
result = python.run("print('Güvenlik Taraması Başlatılıyor')")
```

4. Vektör İşlemleri:
```python
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

# Metin vektörleştirme
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(["güvenlik metni"], embeddings)

# Benzer döküman arama
docs = vectorstore.similarity_search("güvenlik politikası")
```

## Kurulum
İlk olarak gerekli paketleri yükleyelim:
```python
pip install langchain groq
```

Groq API anahtarınızı ayarlayın:
```python
import os
os.environ["GROQ_API_KEY"] = "sizin-api-anahtariniz"
```

## İlk Uygulama: Güvenlik Açığı Analizi
Basit bir güvenlik açığı analiz uygulaması yapalım:

```python
from langchain_groq import ChatGroq
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# LLM'i başlatma
llm = ChatGroq(api_key="sizin-api-anahtariniz")

# Güvenlik açığı analiz şablonu
vuln_template = """
Aşağıdaki güvenlik açığını analiz et:
{vulnerability}

Analiz etmen gereken noktalar:
1. Risk seviyesi
2. Olası etkiler
3. Düzeltme önerileri

Analizi basit ve anlaşılır bir dille yap.
"""

# Prompt şablonunu oluşturma
prompt = PromptTemplate(
    input_variables=["vulnerability"],
    template=vuln_template
)

# Zinciri oluşturma
chain = LLMChain(llm=llm, prompt=prompt)

# Kullanım örneği
sonuc = chain.run("Web sitesinde SQL injection açığı tespit edildi")
print(sonuc)
```

## Sızma Testi Rapor Oluşturucu
Şimdi biraz daha karmaşık bir örnek yapalım. Bu uygulama, sızma testi sonuçlarını otomatik olarak raporlayacak:

```python
from langchain.chains import SequentialChain
from langchain.memory import SimpleMemory

# Bulgu analiz şablonu
finding_template = """
Sızma testi bulgusunu analiz et:
{finding}

Aşağıdaki formatta analiz yap:
- Bulgu Adı
- Risk Seviyesi
- Teknik Detaylar
- Çözüm Önerileri
"""

# Rapor şablonu
report_template = """
Aşağıdaki bulguyu profesyonel bir rapor formatına dönüştür:
{analyzed_finding}

Rapor bu bölümleri içermeli:
1. Yönetici Özeti
2. Teknik Detaylar
3. Düzeltme Adımları
4. Zaman Çizelgesi
"""

# Zincirleri oluşturma
finding_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["finding"],
        template=finding_template
    ),
    output_key="analyzed_finding"
)

report_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["analyzed_finding"],
        template=report_template
    ),
    output_key="final_report"
)

# Zincirleri birleştirme
overall_chain = SequentialChain(
    chains=[finding_chain, report_chain],
    input_variables=["finding"],
    output_variables=["final_report"],
    verbose=True
)
```

## Ağ Tarama Sonuçlarını Değerlendirme
Son olarak, ağ tarama sonuçlarını değerlendiren bir uygulama yapalım:

```python
# Ağ tarama değerlendirme şablonu
scan_template = """
Nmap tarama sonucunu değerlendir:
{scan_result}

Değerlendirme kriterleri:
1. Açık portlar ve servislerin risk analizi
2. Olası güvenlik açıkları
3. Sıkılaştırma önerileri
"""

scan_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["scan_result"],
        template=scan_template
    )
)

# Örnek kullanım
nmap_result = """
PORT     STATE    SERVICE
22/tcp   open     ssh
80/tcp   open     http
443/tcp  open     https
3306/tcp filtered mysql
"""

sonuc = scan_chain.run(scan_result=nmap_result)
```

## Önemli Güvenlik Notları
1. API anahtarlarınızı güvenli bir şekilde saklayın
2. Hassas bilgileri LLM'e göndermeden önce temizleyin
3. Sonuçları her zaman manuel olarak doğrulayın
4. Test ortamında çalışmaya özen gösterin

## Alıştırmalar
1. Basit bir XSS açığını analiz eden bir zincir oluşturun
2. Bir web uygulaması güvenlik taraması raporu oluşturun
3. Kendi özel prompt şablonunuzu tasarlayın

## İleri Seviye Konular
- Memory kullanımı
- Özel araçlarla entegrasyon
- Çoklu LLM kullanımı
- Özel prompt mühendisliği

## Sonuç
Bu eğitimde LangChain'i siber güvenlik alanında nasıl kullanabileceğimizi öğrendik. Örnekleri kendi ihtiyaçlarınıza göre uyarlayabilir ve geliştirebilirsiniz.

Unutmayın: Yapay zeka araçları, siber güvenlik uzmanlarının yerini almaz, onların işini daha verimli hale getirir.
````

2. **Partial Promptlar:**
```python
from langchain.prompts import PromptTemplate
# Bazı değişkenleri önceden doldurma
base_template = PromptTemplate(
    input_variables=["url", "scan_type"],
    template="URL: {url}\nTarama Türü: {scan_type}"
)

# Tarama türünü sabit yapma
nmap_template = base_template.partial(scan_type="Nmap")
```



3. **Şartlı Şablonlar:**

   

```python
conditional_template = PromptTemplate(
    input_variables=["vulnerability", "severity"],
    template="""
    Açık: {vulnerability}
    Seviye: {severity}
    
    {%- if severity == "Yüksek" %}
    ACİL: Hemen müdahale gerekiyor!
    {%- elif severity == "Orta" %}
    UYARI: 24 saat içinde müdahale edilmeli.
    {%- else %}
    BİLGİ: Rutin kontroller sırasında değerlendirilmeli.
    {%- endif %}
    """
)
```



### LangChain'in Temel Komutları

1. **LLM İşlemleri:**
```python
# LLM başlatma
from langchain_groq import ChatGroq
llm = ChatGroq(api_key="your-api-key")

# Basit soru-cevap
response = llm.predict("Bir SQL injection nedir?")

# Sohbet tarzı etkileşim
messages = [
    ("system", "Sen bir güvenlik uzmanısın"),
    ("user", "XSS açığı nedir?")
]
response = llm.predict_messages(messages)
```



2. **Bellek (Memory) İşlemleri:**

```python
from langchain.memory import ConversationBufferMemory

# Basit bellek
memory = ConversationBufferMemory()

# Bellekli zincir
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory
)
```



3. **Araç (Tools) Kullanımı:**



```python
from langchain.tools import DuckDuckGoSearchRun
from langchain.tools import PythonREPLTool

# Arama aracı
search = DuckDuckGoSearchRun()
result = search.run("Son çıkan CVE'ler")

# Python REPL aracı
python = PythonREPLTool()
result = python.run("print('Güvenlik Taraması Başlatılıyor')")
```



4. **Vektör İşlemleri:**

   

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

# Metin vektörleştirme
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(["güvenlik metni"], embeddings)

# Benzer döküman arama
docs = vectorstore.similarity_search("güvenlik politikası")
```



## Kurulum

İlk olarak gerekli paketleri yükleyelim:
```python
pip install langchain groq
```

Groq API anahtarınızı ayarlayın:
```python
import os
os.environ["GROQ_API_KEY"] = "sizin-api-anahtariniz"
```



## İlk Uygulama: Güvenlik Açığı Analizi



Basit bir güvenlik açığı analiz uygulaması yapalım:

```python
from langchain_groq import ChatGroq
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# LLM'i başlatma
llm = ChatGroq(api_key="sizin-api-anahtariniz")

# Güvenlik açığı analiz şablonu
vuln_template = """
Aşağıdaki güvenlik açığını analiz et:
{vulnerability}

Analiz etmen gereken noktalar:
1. Risk seviyesi
2. Olası etkiler
3. Düzeltme önerileri

Analizi basit ve anlaşılır bir dille yap.
"""

# Prompt şablonunu oluşturma
prompt = PromptTemplate(
    input_variables=["vulnerability"],
    template=vuln_template
)

# Zinciri oluşturma
chain = LLMChain(llm=llm, prompt=prompt)

# Kullanım örneği
sonuc = chain.run("Web sitesinde SQL injection açığı tespit edildi")
print(sonuc)
```

## Sızma Testi Rapor Oluşturucu
Şimdi biraz daha karmaşık bir örnek yapalım. Bu uygulama, sızma testi sonuçlarını otomatik olarak raporlayacak:

```python
from langchain.chains import SequentialChain
from langchain.memory import SimpleMemory

# Bulgu analiz şablonu
finding_template = """
Sızma testi bulgusunu analiz et:
{finding}

Aşağıdaki formatta analiz yap:
- Bulgu Adı
- Risk Seviyesi
- Teknik Detaylar
- Çözüm Önerileri
"""

# Rapor şablonu
report_template = """
Aşağıdaki bulguyu profesyonel bir rapor formatına dönüştür:
{analyzed_finding}

Rapor bu bölümleri içermeli:
1. Yönetici Özeti
2. Teknik Detaylar
3. Düzeltme Adımları
4. Zaman Çizelgesi
"""

# Zincirleri oluşturma
finding_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["finding"],
        template=finding_template
    ),
    output_key="analyzed_finding"
)

report_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["analyzed_finding"],
        template=report_template
    ),
    output_key="final_report"
)

# Zincirleri birleştirme
overall_chain = SequentialChain(
    chains=[finding_chain, report_chain],
    input_variables=["finding"],
    output_variables=["final_report"],
    verbose=True
)
```

## Ağ Tarama Sonuçlarını Değerlendirme
Son olarak, ağ tarama sonuçlarını değerlendiren bir uygulama yapalım:

```python
# Ağ tarama değerlendirme şablonu
scan_template = """
Nmap tarama sonucunu değerlendir:
{scan_result}

Değerlendirme kriterleri:
1. Açık portlar ve servislerin risk analizi
2. Olası güvenlik açıkları
3. Sıkılaştırma önerileri
"""

scan_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate(
        input_variables=["scan_result"],
        template=scan_template
    )
)

# Örnek kullanım
nmap_result = """
PORT     STATE    SERVICE
22/tcp   open     ssh
80/tcp   open     http
443/tcp  open     https
3306/tcp filtered mysql
"""

sonuc = scan_chain.run(scan_result=nmap_result)
```

## Önemli Güvenlik Notları
1. API anahtarlarınızı güvenli bir şekilde saklayın
2. Hassas bilgileri LLM'e göndermeden önce temizleyin
3. Sonuçları her zaman manuel olarak doğrulayın
4. Test ortamında çalışmaya özen gösterin

## Alıştırmalar
1. Basit bir XSS açığını analiz eden bir zincir oluşturun
2. Bir web uygulaması güvenlik taraması raporu oluşturun
3. Kendi özel prompt şablonunuzu tasarlayın

## İleri Seviye Konular
- Memory kullanımı
- Özel araçlarla entegrasyon
- Çoklu LLM kullanımı
- Özel prompt mühendisliği

## Sonuç
Bu eğitimde LangChain'i siber güvenlik alanında nasıl kullanabileceğimizi öğrendik. Örnekleri kendi ihtiyaçlarınıza göre uyarlayabilir ve geliştirebilirsiniz.

Unutmayın: Yapay zeka araçları, siber güvenlik uzmanlarının yerini almaz, onların işini daha verimli hale getirir.